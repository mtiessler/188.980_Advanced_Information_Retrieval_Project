{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ba06607",
   "metadata": {},
   "source": [
    "another try with package - under construction\n",
    "\n",
    "bs25s -> example for getting IDs\n",
    "https://github.com/xhluca/bm25s/blob/main/examples/index_with_metadata.py\n",
    "\n",
    "rank_bm25\n",
    "maybe: \n",
    "bm25-pt\n",
    "https://github.com/jxmorris12/bm25_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895d3caf",
   "metadata": {},
   "source": [
    "another try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83861a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource module not available on Windows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hubin\\WorkspaceGIT\\AIR\\188.980_Advanced_Information_Retrieval_Project\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\hubin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hubin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import math\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from collections import defaultdict\n",
    "from rank_bm25 import BM25Okapi\n",
    "from rank_bm25 import BM25L\n",
    "\n",
    "#from tokenizers import Tokenizer\n",
    "\n",
    "import bm25s\n",
    "\n",
    "\n",
    "# Import nltk data\n",
    "# https://www.nltk.org/data.html\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')  # Ensure stopwords are downloaded\n",
    "\n",
    "\n",
    "# set data path\n",
    "\n",
    "data_path_abstract = r\"c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\"\n",
    "\n",
    "# for dev\n",
    "#data_path_abstract = r\"c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\docShort\"\n",
    "\n",
    "\n",
    "data_path_abstract_q = r\"c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\"\n",
    "\n",
    "# os.path.join(data_path_abstract_q, file_name)\n",
    "#data_folder = r\"c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4f2e46",
   "metadata": {},
   "source": [
    "# test with BM25s -> doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61a0e877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 (score: 1.06): ID: 33\n",
      "Rank 2 (score: 0.48): ID: 1234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# test with BM25s\n",
    "# Example for getting IDs:\n",
    "# https://github.com/xhluca/bm25s/blob/main/examples/index_with_metadata.py\n",
    "\n",
    "\"\"\"\n",
    "try bm25s with a corpus of dict\n",
    "\n",
    "Sometimes, you might want to have a corpus consisting of dict rather than pure text.\n",
    "\n",
    "dicts, and any json-serializable object, is supported by bm25s. This example shows you how to pass a list of dict.\n",
    "\n",
    "Note: If the elements in your corpus is not json serializable, it will not be properly saved. In those cases, you \n",
    "should avoid passing \n",
    "\"\"\"\n",
    "import bm25s\n",
    "\n",
    "# Create your corpus here\n",
    "\n",
    "corpus_json = [\n",
    "    {\"id\": 33, \"text\": \"a cat is a feline and likes to purr\", \"metadata\": {\"source\": \"internet\"}},\n",
    "    {\"id\": 44, \"text\": \"a dog is the human's best friend and loves to play\", \"metadata\": {\"source\": \"encyclopedia\"}},\n",
    "    {\"id\": 55, \"text\": \"a bird is a beautiful animal that can fly\", \"metadata\": {\"source\": \"cnn\"}},\n",
    "    {\"id\": 1234, \"text\": \"a fish is a creature that lives in water and swims\", \"metadata\": {\"source\": \"i made it up\"}},\n",
    "]\n",
    "corpus_text = [doc[\"text\"] for doc in corpus_json]\n",
    "\n",
    "\n",
    "# Tokenize the corpus and only keep the ids (faster and saves memory)\n",
    "corpus_tokens = bm25s.tokenize(corpus_text, stopwords=\"en\")\n",
    "\n",
    "# Create the BM25 retriever and attach your corpus_json to it\n",
    "retriever = bm25s.BM25(corpus=corpus_json)\n",
    "# Now, index the corpus_tokens (the corpus_json is not used yet)\n",
    "retriever.index(corpus_tokens)\n",
    "\n",
    "# Query the corpus\n",
    "query = \"does the fish purr like a cat?\"\n",
    "query_tokens = bm25s.tokenize(query)\n",
    "\n",
    "# Get top-k results as a tuple of (doc, scores). Note that results\n",
    "# will correspond to the corpus item at the corresponding index\n",
    "# (you are responsible to make sure each element in corpus_json\n",
    "# corresponds to each element in your tokenized corpus)\n",
    "results, scores = retriever.retrieve(query_tokens, k=2)\n",
    "\n",
    "for i in range(results.shape[1]):\n",
    "    doc, score = results[0, i], scores[0, i]\n",
    "    print(f\"Rank {i+1} (score: {score:.2f}): ID: {doc['id']}\")\n",
    "    #print(f\"Rank {i+1} (score: {score:.2f}): {doc}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c826496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install retriv\n",
    "# Note: SearchEngine is an alias for the SparseRetriever\n",
    "'''from retriv import SearchEngine\n",
    "\n",
    "collection = [\n",
    "  {\"id\": \"doc_1\", \"text\": \"Generals gathered in their masses\"},\n",
    "  {\"id\": \"doc_2\", \"text\": \"Just like witches at black masses\"},\n",
    "  {\"id\": \"doc_3\", \"text\": \"Evil minds that plot destruction\"},\n",
    "  {\"id\": \"doc_4\", \"text\": \"Sorcerer of death's construction\"},\n",
    "]\n",
    "\n",
    "se = SearchEngine(\"new-index\").index(collection)\n",
    "\n",
    "se.search(\"witches masses\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9c2b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install bm25s\n",
    "import bm25s\n",
    "\n",
    "# Create your corpus here\n",
    "corpus = [\n",
    "    \"a cat is a feline and likes to purr\",\n",
    "    \"a dog is the human's best friend and loves to play\",\n",
    "    \"a bird is a beautiful animal that can fly\",\n",
    "    \"a fish is a creature that lives in water and swims\",\n",
    "]\n",
    "\n",
    "# Create the BM25 model and index the corpus\n",
    "retriever = bm25s.BM25(corpus=corpus)\n",
    "retriever.index(bm25s.tokenize(corpus))\n",
    "\n",
    "# Query the corpus and get top-k results\n",
    "query = \"does the fish purr like a cat?\"\n",
    "results, scores = retriever.retrieve(bm25s.tokenize(query), k=2)\n",
    "\n",
    "# Let's see what we got!\n",
    "doc, score = results[0, 0], scores[0, 0]\n",
    "print(doc)\n",
    "\n",
    "#print(f\"Rank {i+1} (score: {score:.2f}): {doc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dfbc75",
   "metadata": {},
   "source": [
    "load data, tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1342512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "# one stream \n",
    "def load_and_preprocess_data(filepath):\n",
    "    stop_words = set(stopwords.words('english'))  # Load English stop words\n",
    "    #stemmer = PorterStemmer()  # PorterStemmer 1/3 slower than SnowballStemmer\n",
    "    stemmer = SnowballStemmer('english')  # Initialize nltk stemmer\n",
    "\n",
    "    documents = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            doc = json.loads(line)\n",
    "            text = f\"{doc.get('title', '')} {doc.get('abstract', '')}\"\n",
    "            authors_text = ' '.join([author.get('name', '').lower() for author in doc.get('authors', [])])\n",
    "            text = f\"{text} {authors_text}\" \n",
    "            text = text.lower()\n",
    "            text = re.sub(r'\\W+', ' ', text)\n",
    "            tokens = word_tokenize(text)\n",
    "            #filtered_tokens = [token for token in tokens if token not in stop_words]  # Remove stop words\n",
    "            # Filter tokens: remove stop words, single characters, and numbers\n",
    "            filtered_tokens = [\n",
    "                token for token in tokens \n",
    "                if token not in stop_words and len(token) > 1 and not token.isdigit()\n",
    "            ]\n",
    "            # Apply steming\n",
    "            stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "            documents.append({\n",
    "                'id': doc.get('id'),\n",
    "                'tokens': stemmed_tokens\n",
    "            })\n",
    "    return documents\n",
    "\n",
    "# returns documents with tokens per stream (=field)  \n",
    "def load_and_preprocess_data_BM25F(filepath):\n",
    "    stop_words = set(stopwords.words('english'))  # Load English stop words\n",
    "    #stemmer = PorterStemmer()  # PorterStemmer 1/3 slower than SnowballStemmer\n",
    "    stemmer = SnowballStemmer('english')  # Initialize nltk stemmer\n",
    "\n",
    "    documents = []\n",
    "    #count_per_field = {'title': 0, 'abstract': 0, 'authors': 0}  # Initialize counts\n",
    "\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            doc = json.loads(line)\n",
    "            \n",
    "            # title tokenization\n",
    "            titel_text = doc.get('title', '').lower()       # convert to lowercase\n",
    "            titel_text = re.sub(r'\\W+', ' ', titel_text)    # replace non-word characters with space\n",
    "            title_tokens = word_tokenize(titel_text)\n",
    "            # Filter tokens: remove stop words, single characters, and numbers\n",
    "            title_tokens = [\n",
    "                token for token in title_tokens\n",
    "                if token not in stop_words and len(token) > 1 and not token.isdigit()\n",
    "            ]\n",
    "            title_tokens = [stemmer.stem(token) for token in title_tokens]\n",
    "\n",
    "            # abstract tokenization\n",
    "            abstract_text = doc.get('abstract', '') or ''  # convert missing to empty string\n",
    "            abstract_text = abstract_text.lower()\n",
    "            abstract_text = re.sub(r'\\W+', ' ', abstract_text)\n",
    "            abstract_tokens = word_tokenize(abstract_text)\n",
    "            # Filter tokens: remove stop words, single characters, and numbers\n",
    "            abstract_tokens = [\n",
    "                token for token in abstract_tokens\n",
    "                if token not in stop_words and len(token) > 1 and not token.isdigit()\n",
    "            ]\n",
    "            abstract_tokens = [stemmer.stem(token) for token in abstract_tokens]\n",
    "\n",
    "            # authors tokenization\n",
    "            # potential: optimize for names of persons\n",
    "            authors_text = ' '.join([author.get('name', '').lower() for author in doc.get('authors', [])])\n",
    "            authors_text = re.sub(r'\\W+', ' ', authors_text)\n",
    "            authors_tokens = word_tokenize(authors_text)\n",
    "            # Filter tokens: remove stop words, single characters, and numbers\n",
    "            authors_tokens = [\n",
    "                token for token in authors_tokens\n",
    "                if token not in stop_words and len(token) > 1 and not token.isdigit()\n",
    "            ]\n",
    "            authors_tokens = [stemmer.stem(token) for token in authors_tokens]\n",
    "            \n",
    "            # Combine all tokens\n",
    "            documents.append({\n",
    "                'id': doc.get('id'),\n",
    "                #'tokens': stemmed_tokens,\n",
    "                'title': title_tokens,\n",
    "                'abstract': abstract_tokens,\n",
    "                'authors': authors_tokens\n",
    "            })\n",
    "\n",
    "            # calculate number of tokens per field\n",
    "            #count_per_field['title'] += len(title_tokens)\n",
    "            #count_per_field['abstract'] += len(abstract_tokens)\n",
    "            #count_per_field['authors'] += len(authors_tokens)\n",
    "            \n",
    "    # number of documents\n",
    "    #doc_count = len(documents)\n",
    "    return documents #, doc_count, count_per_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec595ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process all files in a folder\n",
    "def load_and_preprocess_folder(folder_path):\n",
    "    all_documents = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jsonl'):\n",
    "            filepath = os.path.join(folder_path, filename)\n",
    "            print(f\"Processing file: {filepath}\")\n",
    "            documents = load_and_preprocess_data(filepath)\n",
    "            all_documents.extend(documents)\n",
    "    return all_documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48564dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\\documents_000001.jsonl\n",
      "Processing file: c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\\documents_000002.jsonl\n",
      "Processing file: c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\\documents_000003.jsonl\n",
      "Processing file: c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\\documents_000004.jsonl\n",
      "Processing file: c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\\documents_000005.jsonl\n",
      "Processing file: c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\\documents_000006.jsonl\n",
      "Processing file: c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\\documents_000007.jsonl\n",
      "Processing file: c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\\documents_000008.jsonl\n",
      "Processing file: c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\\documents_000009.jsonl\n",
      "Processing file: c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\\documents_000010.jsonl\n",
      "Processing file: c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\\documents_000011.jsonl\n",
      "Processing file: c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\\documents_000012.jsonl\n",
      "Processing file: c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\\documents_000013.jsonl\n",
      "Processing file: c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\\documents_000014.jsonl\n",
      "Processing file: c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\\documents_000015.jsonl\n",
      "Processing file: c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\\documents_000016.jsonl\n",
      "Processing file: c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\\documents_000017.jsonl\n",
      "Processing file: c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\\documents_000018.jsonl\n",
      "Processing file: c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\\documents_000019.jsonl\n",
      "Processing file: c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\\documents_000020.jsonl\n",
      "Processing file: c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\\documents_000021.jsonl\n",
      "Loaded 2014265 documents from folder.\n"
     ]
    }
   ],
   "source": [
    "#data_folder = r\"c:\\Users\\hubin\\TULokal\\AIRLocal\\longeval_sci_training_2025_abstract\\longeval_sci_training_2025_abstract\\documents\"\n",
    "all_documents = load_and_preprocess_folder(data_path_abstract)\n",
    "print(f\"Loaded {len(all_documents)} documents from folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "390c0e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from rank_bm25 import BM25L\n",
    "import numpy as np\n",
    "\n",
    "tokenized_docs = [doc['tokens'] for doc in all_documents]\n",
    "\n",
    "bm25L = BM25L(tokenized_docs) # takes lenght of documents into account\n",
    "#bm25 = BM25Okapi(tokenized_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67f5d3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '44716561', 'tokens': ['quantum', 'dot', 'base', 'singl', 'photon', 'sourc', 'light', 'matter', 'interfac', 'die', 'quanteninformationstechnologi', 'ist', 'ein', 'schwerpunkt', 'intensiv', 'weltweit', 'forschungsarbeit', 'da', 'sie', 'lösungen', 'für', 'aktuell', 'global', 'problem', 'verspricht', 'bietet', 'die', 'quantenkommunik', 'qkd', 'engl', 'quantum', 'key', 'distribut', 'absolut', 'abhörsicher', 'kommunikationsprotokoll', 'und', 'könnte', 'mit', 'der', 'realisierung', 'von', 'quantenrepeatern', 'auch', 'über', 'große', 'distanzen', 'zum', 'einsatz', 'kommen', 'quantencomput', 'engl', 'quantum', 'comput', 'könnten', 'von', 'nutzen', 'sein', 'um', 'sehr', 'schwierig', 'und', 'komplex', 'mathematisch', 'problem', 'schneller', 'zu', 'lösen', 'ein', 'grundlegend', 'kritisch', 'baustein', 'der', 'gesamten', 'halbleiterbasierten', 'quanteninformationsverarbeitung', 'qip', 'engl', 'quantum', 'inform', 'process', 'ist', 'die', 'bereitstellung', 'von', 'proben', 'die', 'einerseit', 'die', 'geforderten', 'physikalischen', 'eigenschaften', 'aufweisen', 'und', 'andererseit', 'den', 'anforderungen', 'der', 'komplexen', 'messtechnik', 'genügen', 'um', 'die', 'quanteneigenschaften', 'nachzuweisen', 'und', 'technologisch', 'nutzbar', 'machen', 'zu', 'können', 'halbleiterbasierten', 'ansätzen', 'haben', 'sich', 'quantenpunkt', 'al', 'sehr', 'vielversprechend', 'kandidaten', 'für', 'dies', 'experiment', 'etabliert', 'halbleiterquantenpunkt', 'weisen', 'große', 'ähnlichkeiten', 'zu', 'einzelnen', 'atomen', 'auf', 'die', 'sich', 'durch', 'diskret', 'energieniveaus', 'und', 'diskret', 'spektrallinien', 'im', 'emissionsspektrum', 'manifestieren', 'und', 'zeichnen', 'sich', 'überdi', 'al', 'exzellent', 'emitt', 'für', 'einzeln', 'und', 'ununterscheidbar', 'photonen', 'aus', 'außerdem', 'können', 'mit', 'quantenpunkten', 'zwei', 'kritisch', 'baustein', 'der', 'quanteninformationstechnologi', 'abgedeckt', 'werden', 'können', 'stationär', 'quantenbit', 'qubit', 'form', 'von', 'elektronenspinzuständen', 'gespeichert', 'werden', 'und', 'mittel', 'spin', 'photon', 'verschränkung', 'weit', 'entfernt', 'stationär', 'qubit', 'über', 'fliegend', 'photonisch', 'qubit', 'verschränkt', 'werden', 'die', 'herstellung', 'und', 'charakterisierung', 'von', 'quantenpunktbasierten', 'halbleiterproben', 'die', 'sich', 'durch', 'definiert', 'eigenschaften', 'für', 'experiment', 'der', 'qip', 'auszeichnen', 'steht', 'im', 'mittelpunkt', 'der', 'vorliegenden', 'arbeit', 'die', 'basi', 'für', 'das', 'probenwachstum', 'bildet', 'dabei', 'das', 'materialsystem', 'von', 'selbstorganisierten', 'ga', 'quantenpunkten', 'auf', 'gaa', 'substraten', 'die', 'herstellung', 'der', 'quantenpunktproben', 'mittel', 'molekularstrahlepitaxi', 'ermöglicht', 'höchste', 'kristallin', 'qualitäten', 'und', 'bietet', 'die', 'möglichkeit', 'die', 'quantenemitt', 'photonisch', 'resonatoren', 'zu', 'integrieren', 'dadurch', 'kann', 'die', 'lichtauskoppeleffizienz', 'stark', 'erhöht', 'und', 'die', 'emiss', 'durch', 'effekt', 'der', 'licht', 'materi', 'wechselwirkung', 'verstärkt', 'werden', 'vor', 'diesem', 'hintergrund', 'wurden', 'der', 'vorliegenden', 'arbeit', 'verschieden', 'ga', 'quantenpunktproben', 'mit', 'definierten', 'anforderungen', 'mittel', 'molekularstrahlepitaxi', 'hergestellt', 'und', 'deren', 'morphologisch', 'und', 'optisch', 'eigenschaften', 'untersucht', 'für', 'die', 'charakterisierung', 'der', 'morphologi', 'kamen', 'rasterelektronen', 'und', 'rasterkraftmikroskopi', 'zum', 'einsatz', 'die', 'optischen', 'eigenschaften', 'wurden', 'mit', 'hilf', 'der', 'reflekt', 'photolumineszenz', 'und', 'resonanzfluoreszenz', 'spektroskopi', 'sowi', 'autokorrelationsmessungen', 'zweiter', 'ordnung', 'ermittelt', 'der', 'experimentalteil', 'der', 'arbeit', 'ist', 'drei', 'kapitel', 'unterteilt', 'deren', 'kerninhalt', 'im', 'folgenden', 'kurz', 'wiedergegeben', 'werden', 'quasi', 'planar', 'einzelphotonenquell', 'mit', 'hoher', 'extraktionseffizienz', 'planar', 'quantenpunktbasiert', 'einzelphotonenquellen', 'mit', 'hoher', 'extraktionseffizienz', 'sind', 'für', 'experiment', 'zur', 'spinmanipul', 'von', 'herausragend', 'bedeutung', 'elektronen', 'und', 'lochspin', 'haben', 'sich', 'al', 'gute', 'kandidaten', 'erwiesen', 'um', 'gezielt', 'einzeln', 'elektronenspin', 'zu', 'initialisieren', 'manipulieren', 'und', 'zu', 'messen', 'ein', 'einzeln', 'quantenpunkt', 'muss', 'einfach', 'geladen', 'sein', 'damit', 'er', 'im', 'voigt', 'magnetfeld', 'ein', 'system', 'bilden', 'kann', 'welch', 'die', 'grundlegend', 'konfigur', 'für', 'experiment', 'dieser', 'art', 'darstellt', 'wichtig', 'sind', 'hier', 'einerseit', 'ein', 'stabil', 'spinkonfigur', 'mit', 'langer', 'kohärenzzeit', 'und', 'andererseit', 'hohe', 'lichtauskoppeleffizienzen', 'quantenpunkt', 'planaren', 'mikrokavitäten', 'weisen', 'größere', 'wert', 'für', 'die', 'spindephasierungszeit', 'auf', 'al', 'mikro', 'und', 'nanotürmchenresonatoren', 'dagegen', 'ist', 'bei', 'planaren', 'proben', 'die', 'lichtauskoppeleffizienz', 'gering', 'diesem', 'kapitel', 'wird', 'ein', 'quasi', 'planar', 'quantenpunktbasiert', 'quell', 'für', 'einzeln', 'und', 'ununterscheidbar', 'photonen', 'indist', 'mit', 'hoher', 'reinheit', 'vorgestellt', 'die', 'quantenpunktemiss', 'weist', 'ein', 'sehr', 'hohe', 'intensität', 'und', 'optisch', 'qualität', 'mit', 'halbwertsbreiten', 'nahe', 'der', 'natürlichen', 'linienbreit', 'auf', 'die', 'auskoppeleffizienz', 'wurd', 'zu', 'für', 'rein', 'einzelphotonenemiss', 'bestimmt', 'und', 'übersteigt', 'damit', 'die', 'für', 'ein', 'planar', 'resonatorstruktur', 'erwartet', 'extraktionseffizienz', 'deutlich', 'al', 'grund', 'hierfür', 'konnt', 'die', 'kopplung', 'der', 'photonenemiss', 'gallium', 'induziert', 'gauß', 'artig', 'defektstrukturen', 'ausgemacht', 'werden', 'mithilf', 'morphologisch', 'untersuchungen', 'und', 'simulationen', 'wurd', 'gezeigt', 'dass', 'dies', 'defektkavitäten', 'einerseit', 'al', 'nukleationszentren', 'für', 'das', 'quantenpunktwachstum', 'dienen', 'und', 'andererseit', 'die', 'extrakt', 'des', 'emittierten', 'licht', 'der', 'darunterliegenden', 'quantenpunkt', 'durch', 'lichtbündelung', 'verbessern', 'weiterführenden', 'arbeiten', 'konnt', 'dieser', 'spezifischen', 'probe', 'der', 'fundamental', 'effekt', 'der', 'verschränkung', 'von', 'elektronenspin', 'und', 'photon', 'nachgewiesen', 'werden', 'der', 'einen', 'kritischen', 'baustein', 'für', 'halbleiterbasiert', 'quantenrepeat', 'darstellt', 'im', 'rahmen', 'dies', 'experi', 'war', 'es', 'möglich', 'die', 'komplett', 'tomographi', 'ein', 'verschränkten', 'spin', 'photon', 'paar', 'einer', 'halbleiterbasierten', 'spin', 'photon', 'schnittstell', 'zu', 'messen', 'überdi', 'konnt', 'zweiphotoneninterferenz', 'und', 'ununterscheidbarkeit', 'von', 'photonen', 'aus', 'zwei', 'räumlich', 'getrennten', 'quantenpunkten', 'auf', 'diesem', 'wafer', 'gemessen', 'werden', 'ebenfal', 'einen', 'kritischen', 'baustein', 'für', 'quantenrepeat', 'darstellt', 'gekoppelt', 'quantenfilm', 'quantenpunkt', 'system', 'weiter', 'herausforderungen', 'für', 'optisch', 'kontrolliert', 'halbleiterbasiert', 'spin', 'qubit', 'system', 'sind', 'das', 'schnell', 'und', 'zerstörungsfrei', 'auslesen', 'der', 'spin', 'inform', 'sowi', 'die', 'implementierung', 'ein', 'skalierbaren', 'ein', 'qubit', 'und', 'zwei', 'qubit', 'gatter', 'ein', 'kürzlich', 'veröffentlicht', 'theoretisch', 'konzept', 'könnte', 'hierzu', 'einen', 'eleganten', 'weg', 'eröffnen', 'hierbei', 'wird', 'die', 'spinabhängig', 'austauschwechselwirkung', 'zwischen', 'einem', 'elektron', 'spin', 'einem', 'quantenpunkt', 'und', 'einem', 'exziton', 'polariton', 'gas', 'welch', 'einem', 'nahegelegenen', 'quantenfilm', 'eingebettet', 'ist', 'ausgenützt', 'könnte', 'die', 'spin', 'inform', 'zerstörungsfrei', 'ausgelesen', 'werden', 'und', 'ein', 'skalierbar', 'wechselwirkung', 'zwischen', 'zwei', 'qubit', 'über', 'größere', 'distanzen', 'ermöglicht', 'werden', 'da', 'sich', 'die', 'wellenfunkt', 'von', 'exziton', 'polaritonen', 'abhängig', 'von', 'der', 'güte', 'des', 'mikroreson', 'über', 'mehrer', 'μm', 'ausdehnen', 'kann', 'die', 'und', 'weiter', 'möglich', 'anwendungen', 'machen', 'das', 'gekoppelt', 'quantenfilm', 'quantenpunkt', 'system', 'sehr', 'interess', 'weshalb', 'ein', 'grundlegend', 'experimentell', 'untersuchung', 'dies', 'system', 'wünschenswert', 'ist', 'zusammenarbeit', 'mit', 'der', 'arbeitsgrupp', 'um', 'yoshihisa', 'yamamoto', 'der', 'universität', 'stanford', 'wurd', 'hierzu', 'ein', 'konkret', 'probendesign', 'entwickelt', 'und', 'im', 'rahmen', 'dieser', 'arbeit', 'technologisch', 'verwirklicht', 'durch', 'systematisch', 'epitaktisch', 'optimierung', 'ist', 'es', 'gelungen', 'ein', 'gekoppelt', 'quantenfilm', 'quantenpunkt', 'system', 'erfolgreich', 'einen', 'mikroreson', 'zu', 'implementierten', 'das', 'exziton', 'polariton', 'gas', 'konnt', 'mittel', 'ein', 'quantenfilm', 'starker', 'kopplung', 'einer', 'mikrokavität', 'mit', 'einer', 'rabi', 'aufspaltung', 'von', 'vr', 'mev', 'verwirklicht', 'werden', 'zudem', 'konnten', 'einfach', 'geladen', 'quantenpunkt', 'mit', 'hoher', 'optisch', 'qualität', 'und', 'klarem', 'einzelphotonencharakt', 'unmittelbar', 'nähe', 'zum', 'quantenfilm', 'gemessen', 'werden', 'positioniert', 'quantenpunkt', 'für', 'die', 'herstellung', 'quantenpunktbasiert', 'einzelphotonenquellen', 'mit', 'hoher', 'optisch', 'qualität', 'ist', 'ein', 'skalierbar', 'technologisch', 'produktionsplattform', 'wünschenswert', 'dazu', 'müssen', 'einzeln', 'quantenpunkt', 'positionierbar', 'und', 'somit', 'deterministisch', 'und', 'skalierbar', 'bauteil', 'integriert', 'werden', 'können', 'basierend', 'auf', 'zweidimensionalen', 'regelmäßig', 'angeordneten', 'und', 'dadurch', 'adressierbaren', 'quantenpunkten', 'gibt', 'es', 'zudem', 'ein', 'konzept', 'um', 'ein', 'skalierbar', 'optisch', 'kontrolliert', 'zwei', 'qubit', 'gatter', 'zu', 'realisieren', 'das', 'hier', 'verfolgt', 'prinzip', 'für', 'die', 'positionierung', 'von', 'quantenpunkten', 'beruht', 'auf', 'der', 'verwendung', 'von', 'vorstrukturierten', 'substraten', 'mit', 'geätzten', 'nanolöchern', 'welch', 'al', 'nukleationszentren', 'für', 'das', 'quantenpunktwachstum', 'dienen', 'durch', 'ein', 'optimiert', 'schichtstruktur', 'und', 'ein', 'erhöht', 'lichtauskopplung', 'unter', 'verwendung', 'ein', 'dielektrischen', 'spiegel', 'konnt', 'erstmal', 'resonanzfluoreszenz', 'einem', 'positionierten', 'quantenpunkt', 'gemessen', 'werden', 'einem', 'weiteren', 'optimierungsansatz', 'konnt', 'außerdem', 'emiss', 'von', 'positionierten', 'ingaa', 'quantenpunkten', 'auf', 'gaa', 'substrat', 'bei', 'μm', 'telekommunikationswellenläng', 'erreicht', 'werden', 'quantum', 'inform', 'technolog', 'focus', 'worldwid', 'intens', 'research', 'promis', 'solut', 'current', 'global', 'problem', 'tap', 'proof', 'communic', 'protocol', 'field', 'quantum', 'key', 'distribut', 'qkd', 'could', 'revolution', 'broadcast', 'sensit', 'data', 'would', 'also', 'avail', 'larg', 'distanc', 'communic', 'realize', 'quantum', 'repeat', 'system', 'quantum', 'comput', 'could', 'use', 'dramat', 'fasten', 'solut', 'difficult', 'complex', 'mathemat', 'problem', 'critic', 'build', 'block', 'solid', 'state', 'base', 'quantum', 'inform', 'process', 'qip', 'alloc', 'semiconductor', 'sampl', 'one', 'side', 'provid', 'desir', 'quantum', 'mechan', 'featur', 'side', 'satisfi', 'requir', 'complex', 'non', 'demolit', 'measur', 'techniqu', 'semiconductor', 'quantum', 'dot', 'promis', 'candid', 'solid', 'state', 'base', 'approach', 'act', 'like', 'artifici', 'atom', 'manifest', 'discret', 'emiss', 'line', 'excel', 'emitt', 'singl', 'indistinguish', 'photon', 'moreov', 'save', 'quantum', 'inform', 'stationari', 'quantum', 'bit', 'qubit', 'electron', 'spin', 'emit', 'fli', 'photon', 'qubit', 'entangl', 'remot', 'qubit', 'via', 'spin', 'photon', 'entangl', 'fabric', 'character', 'quantum', 'dot', 'base', 'semiconductor', 'sampl', 'serv', 'basic', 'build', 'block', 'experi', 'field', 'qip', 'pre', 'defin', 'physic', 'featur', 'focus', 'present', 'thesi', 'basic', 'materi', 'system', 'consist', 'ga', 'quantum', 'dot', 'gaa', 'substrat', 'growth', 'quantum', 'dot', 'base', 'semiconductor', 'sampl', 'via', 'molecular', 'beam', 'epitaxi', 'offer', 'highest', 'crystal', 'qualiti', 'possibl', 'integr', 'quantum', 'emitt', 'photon', 'reson', 'improv', 'light', 'outcoupl', 'effici', 'enhanc', 'emiss', 'light', 'matter', 'coupl', 'effect', 'background', 'thesi', 'focuss', 'prepar', 'character', 'differ', 'ga', 'base', 'quantum', 'dot', 'sampl', 'morpholog', 'properti', 'character', 'via', 'scannnig', 'electron', 'microscopi', 'atom', 'forc', 'microscopi', 'character', 'optic', 'properti', 'perform', 'spectroscopi', 'reflect', 'photoluminesc', 'reson', 'fluoresc', 'signal', 'well', 'measur', 'second', 'order', 'correl', 'function', 'main', 'part', 'divid', 'three', 'chapter', 'briefli', 'summar', 'quasi', 'planar', 'singl', 'photon', 'sourc', 'high', 'extract', 'effici', 'planar', 'quantum', 'dot', 'base', 'high', 'effici', 'singl', 'photon', 'sourc', 'great', 'import', 'quantum', 'dot', 'electron', 'hole', 'spin', 'turn', 'promis', 'candid', 'spin', 'manipul', 'experi', 'abl', 'intial', 'manipul', 'measur', 'singl', 'electron', 'spin', 'quantum', 'dot', 'charg', 'singl', 'electron', 'build', 'system', 'magnet', 'field', 'voigt', 'geometri', 'import', 'one', 'side', 'spin', 'configur', 'stabl', 'compris', 'long', 'spin', 'coher', 'time', 'side', 'photon', 'outcoupl', 'effici', 'high', 'enough', 'measur', 'quantum', 'dot', 'planar', 'microcav', 'larg', 'spin', 'coher', 'time', 'rather', 'weak', 'outcoupl', 'effici', 'compar', 'micro', 'nanopillar', 'reson', 'chapter', 'quasi', 'planar', 'quantum', 'dot', 'base', 'sourc', 'singl', 'indistinguish', 'photon', 'indist', 'high', 'puriti', 'present', 'planar', 'asymmetr', 'microcav', 'open', 'surfac', 'close', 'proxim', 'activ', 'layer', 'spin', 'dephas', 'minim', 'optic', 'qualiti', 'quantum', 'dot', 'high', 'emiss', 'linewidth', 'near', 'natur', 'linewidth', 'quantum', 'dot', 'addit', 'singl', 'photon', 'sourc', 'show', 'high', 'outcoupl', 'effici', 'exceed', 'outcoupl', 'regular', 'planar', 'reson', 'high', 'extract', 'effici', 'attribut', 'coupl', 'photon', 'emiss', 'gallium', 'induc', 'gaussian', 'shape', 'nanohil', 'defect', 'morpholog', 'investig', 'simul', 'show', 'defect', 'caviti', 'structur', 'serv', 'nucleat', 'center', 'quantum', 'dot', 'growth', 'increas', 'outcoupl', 'effici', 'lens', 'effect', 'experi', 'specif', 'sampl', 'entangl', 'electron', 'spin', 'photon', 'demonstr', 'critic', 'build', 'block', 'semiconductor', 'base', 'quantum', 'repeat', 'context', 'also', 'full', 'tomographi', 'polar', 'entangl', 'spin', 'photon', 'pair', 'measur', 'surpris', 'high', 'fidel', 'moreov', 'two', 'photon', 'interfer', 'indistinguish', 'two', 'photon', 'remot', 'quantum', 'dot', 'wafer', 'measur', 'also', 'constitut', 'critic', 'build', 'block', 'quantum', 'repeat', 'coupl', 'quantum', 'well', 'quantum', 'dot', 'system', 'challeng', 'optic', 'control', 'spin', 'qubit', 'system', 'fast', 'readout', 'quantum', 'inform', 'high', 'fidel', 'implement', 'scalabl', 'one', 'two', 'qubit', 'gate', 'therefor', 'propos', 'adapt', 'base', 'coupl', 'electron', 'spin', 'quantum', 'dot', 'gas', 'exciton', 'polariton', 'form', 'quantum', 'well', 'close', 'proxim', 'quantum', 'dot', 'cooper', 'yoshihisa', 'yamamoto', 'group', 'stanford', 'univers', 'sampl', 'structur', 'design', 'technolog', 'realiz', 'part', 'thesi', 'studi', 'fundament', 'physic', 'properti', 'coupl', 'system', 'systemat', 'epitact', 'improv', 'coupl', 'quantum', 'well', 'quantum', 'dot', 'system', 'could', 'success', 'implement', 'microreson', 'exciton', 'polariton', 'gas', 'realiz', 'quantum', 'well', 'strong', 'coupl', 'microcav', 'rabi', 'split', 'vr', 'mev', 'although', 'distanc', 'quantum', 'well', 'nm', 'charg', 'quantum', 'dot', 'high', 'optic', 'qualiti', 'clear', 'singl', 'photon', 'emiss', 'charact', 'could', 'measur', 'site', 'control', 'quantum', 'dot', 'scalabl', 'technolog', 'platform', 'bright', 'sourc', 'quantum', 'light', 'high', 'desir', 'site', 'control', 'quantum', 'dot', 'high', 'optic', 'qualiti', 'promis', 'candid', 'realiz', 'system', 'concept', 'offer', 'possibl', 'integr', 'singl', 'quantum', 'dot', 'devic', 'determinist', 'scalabl', 'way', 'furthermor', 'provid', 'sampl', 'structur', 'regular', 'two', 'dimension', 'array', 'site', 'control', 'quantum', 'dot', 'realiz', 'concept', 'optic', 'control', 'two', 'qubit', 'gate', 'method', 'posit', 'quantum', 'dot', 'use', 'thesi', 'base', 'etch', 'nanohol', 'pre', 'pattern', 'substrat', 'serv', 'nucleat', 'center', 'quantum', 'dot', 'growth', 'process', 'optim', 'layer', 'structur', 'increas', 'light', 'outcoupl', 'effici', 'use', 'dielectr', 'mirror', 'allow', 'first', 'measur', 'reson', 'fluoresc', 'site', 'control', 'quantum', 'dot', 'optim', 'design', 'emiss', 'posit', 'quantum', 'dot', 'μm', 'telecommun', 'wavelength', 'demonstr', 'first', 'time', 'ingaa', 'quantum', 'dot', 'gaa', 'substrat', 'maier', 'sebastian']}, {'id': '97643030', 'tokens': ['측정기기에', '무관한', '양자조정과', '양자', '채널조정의', '검증', '학위논문', '박사', '서울대학교', '대학원', '자연과학대학', '물리', '천문학부', '물리학전공', '정현석', '논문은', '손실을', '견딜', '있는', '양자조정과', '양자', '채널조정에', '대해', '측정기기에', '무관한', '검증방법을', '제공하는', '것을', '목표로', '삼고', '있다', '논문에서는', '양자', '비국소성의', '개념들과', '검증과정에', '있어서', '가정되는', '신뢰성의', '여부에', '따라', '비국소성의', '범주를', '분류할', '있음을', '살펴본다', '검증에', '참여하는', '모든', '검증자를', '신뢰할', '있을때', '검증하는', '양자', '비국소성을', '양자얽힘이라고', '하고', '모든', '검증자를', '신뢰할', '없을', '검증하는', '양자', '비국소성을', '비국소성이라고', '하며', '몇몇', '검증자는', '신뢰할', '있으나', '나머지', '검증자는', '신뢰할', '없는', '경우에', '검증하는', '양자', '비국소성을', '양자조정이라고', '한다', '이러한', '관점에서', '양자조정은', '비국소성과', '양자얽힘의', '가운데에', '위치하는', '비국소성이다', '비국소적', '현상을', '보여줄', '있는', '양자상태의', '관점에서', '말한다면', '양자조정이', '가능한', '상태들의', '집합은', '비국소적', '상태들의', '집합보다', '크고', '양자', '얽힘이', '있는', '상태들의', '집합은', '양자조정이', '가능한', '상태들의', '집합보다', '크다', '어떠한', '이유로', '인해', '모든', '검증자를', '신뢰할', '수는', '없는', '상황이라면', '양자얽힘의', '검증은', '불가능하고', '따라서', '남게되는', '선택지는', '양자조정이나', '비국소성으로', '좁혀진다', '따라서', '양자조정은', '특정', '검증자를', '신뢰할', '없는', '상황에서', '최대한', '많은', '양자상태를', '선택지로', '확보하고', '싶을', '유용하게', '활용될', '있는', '비국소성의', '범주이다', '한편', '양자얽힘과', '양자조정의', '검증에', '있어', '특정', '검증자를', '신뢰할', '있어야', '한다는', '요구조건을', '완화하여', '특정', '양자상태를', '생성할', '있어야', '한다는', '요구조건으로', '대체하는', '검증', '방안이', '존재한다', '측정기기에', '무관한', '검증이라고', '불리는', '이러한', '검증', '방법은', '비국소성', '놀이에서', '입력값을', '고전', '정보가', '아닌', '양자', '상태로', '바꾸는', '방식으로', '이루어진다', '놀이의', '참여자들은', '입력된', '양자상태를', '명확하게', '구분', '방법이', '없으므로', '비국소적', '양자상태를', '공유하지', '않는다면', '놀이에서', '높은', '점수를', '얻지', '못하게', '되고', '따라서', '비국소성의', '검증을', '통과할', '없다', '논문에서는', '측정기기에', '무관한', '검증방법을', '손실을', '견딜', '있는', '양자조정에', '접목하였다', '이렇게', '구성된', '양자조정의', '검증은', '손실을', '견딜', '있는', '특성과', '측정기기에', '무관한', '특성을', '모두', '가지며', '조정되는', '검증자에게서', '조정하는', '검증자에게', '정보', '전송을', '허용하더라도', '유효하고', '심지어', '양자', '상태의', '생성이', '불완전하더라도', '여전히', '유효함을', '보일', '있다', '불완전한', '양자상태의', '생성이', '양자조정의', '검증에', '미치는', '영향은', '큐빗', '상황에서', '양화하였다', '이러한', '양자조정의', '검증은', '손실에', '견디는', '특성이', '비대칭적인데', '조정되는', '검증자가', '겪는', '손실은', '검증에', '영향을', '끼치지', '않으나', '조정하는', '검증자가', '겪는', '손실을', '견디기', '위해서는', '양자조정의', '검증방안을', '적절히', '재구성해야만', '한다', '이러한', '비대칭성은', '비대칭적인', '양자', '정보처리', '과제에', '응용될', '있으며', '손실에', '견딜', '있는', '특성과', '측정기기에', '무관한', '특성은', '잡음이', '많고', '통제할', '없는', '환경에서', '비국소성의', '검증을', '구현하는', '도움이', '것이라고', '기대된다', '한편', '우리는', '양자', '비국소성의', '개념을', '양자', '채널로', '확장하여', '측정기기에', '무관한', '양자', '채널조정의', '방법을', '제안하였다', '이를', '위해', '상태가', '아닌', '집합체', '개념을', '채택하여', '문제에', '접근하였고', '자미올코프스키', '동형사상을', '이용하여', '채널', '집합체가', '양자조정', '가능하다는', '사실과', '쌍대', '양자상태', '집합체가', '양자조정', '가능하다는', '사실이', '동치조건임을', '증명하였다', '정리된', '측정기기에', '독립적인', '검증방안을', '쌍대', '양자상태에', '적용하여', '측정기기에', '독립적인', '채널', '조정의', '검증을', '완수한다', '나아가', '불완전한', '양자상태의', '생성이', '측정기기에', '독립적인', '검증에', '미치는', '영향을', '분석하였는데', '특히', '자미올코프스키', '동형사상을', '얻는데', '쓰이는', '양자상태에', '집중하였다', '결과', '목표로', '삼았던', '순수한', '양자상태를', '생성해내지', '하고', '다른', '양자상태를', '만들더라도', '사이의', '순수한', '양자상태가', '슈미트', '랭크를', '가지기만', '한다면', '검증과정에는', '어떠한', '문제도', '일으키지', '않음을', '보였고', '국소적인', '잡음과', '섞이는', '경우', '어느', '정도의', '잡음의', '비율까지는', '견딜', '있음을', '보였다', '이때', '견딜', '있는', '잡음의', '비율의', '하한은', '이미', '알려져', '있는', '조정', '억셈도로', '결정된다', '추가적인', '연구', '발전방향을', '위하여', '양자조정', '억셈도', '그와', '유사한', '형태의', '물리량과', '양자조정및', '자미올코프스키', '동형사상과', '관련된', '가지', '미해결', '문제들을', '던져두었다', '측정기기에', '무관한', '양자', '채널조정의', '검증은', '통제할', '없고', '잡음이', '많은', '상황에서', '양자', '채널의', '양자정보가', '누출되는', '상황을', '확인하는데', '유용하게', '사용될', '것으로', '기대된다', 'dissert', 'aim', 'provid', 'measur', 'devic', 'independ', 'verif', 'protocol', 'loss', 'toler', 'quantum', 'steer', 'quantum', 'channel', 'steer', 'review', 'concept', 'quantum', 'nonloc', 'see', 'classifi', 'three', 'depend', 'assumpt', 'parti', 'particip', 'verif', 'protocol', 'trustworthi', 'quantum', 'nonloc', 'verifi', 'everi', 'parti', 'trust', 'call', 'quantum', 'entangl', 'verifi', 'everi', 'parti', 'untrust', 'call', 'bell', 'nonloc', 'verifi', 'parti', 'trust', 'other', 'call', 'quantum', 'steer', 'respect', 'quantum', 'steer', 'lie', 'intermedi', 'posit', 'bell', 'nonloc', 'quantum', 'entangl', 'view', 'quantum', 'state', 'display', 'nonloc', 'phenomenon', 'say', 'set', 'steerabl', 'state', 'larger', 'set', 'bell', 'nonloc', 'state', 'set', 'entangl', 'state', 'larger', 'set', 'steerabl', 'state', 'situat', 'trust', 'everybodi', 'entangl', 'verif', 'imposs', 'thus', 'option', 'steer', 'bell', 'nonloc', 'therefor', 'quantum', 'steer', 'use', 'parti', 'trust', 'need', 'broad', 'choic', 'quantum', 'state', 'exploit', 'quantum', 'nonloc', 'meantim', 'anoth', 'verif', 'protocol', 'quantum', 'nonloc', 'reliev', 'trust', 'assumpt', 'cost', 'quantum', 'state', 'generat', 'protocol', 'call', 'measur', 'devic', 'independ', 'verif', 'protocol', 'construct', 'nonloc', 'game', 'approach', 'classic', 'input', 'replac', 'quantum', 'state', 'particip', 'game', 'distinguish', 'input', 'state', 'share', 'quantum', 'nonloc', 'state', 'thus', 'success', 'game', 'obtain', 'high', 'score', 'indic', 'quantum', 'nonloc', 'share', 'state', 'appli', 'measur', 'devic', 'independ', 'protocol', 'loss', 'toler', 'steer', 'inequ', 'result', 'construct', 'quantum', 'steer', 'verif', 'protocol', 'measur', 'devic', 'independ', 'loss', 'toler', 'verif', 'valid', 'even', 'allow', 'one', 'way', 'communic', 'steer', 'parti', 'steer', 'parti', 'generat', 'input', 'quantum', 'state', 'imperfect', 'effect', 'imperfect', 'generat', 'input', 'quantum', 'state', 'verif', 'protocol', 'quantifi', 'two', 'qubit', 'setup', 'result', 'steer', 'criterion', 'asymmetr', 'respect', 'measur', 'effici', 'measur', 'effici', 'steer', 'parti', 'affect', 'verif', 'protocol', 'steer', 'parti', 'therefor', 'make', 'steer', 'verif', 'loss', 'toler', 'respect', 'steer', 'parti', 'reformul', 'appropri', 'accord', 'herald', 'effici', 'steer', 'parti', 'measur', 'devic', 'independ', 'loss', 'toler', 'properti', 'help', 'implement', 'steer', 'verif', 'uncontrol', 'lossi', 'environ', 'asymmetr', 'properti', 'use', 'asymmetr', 'quantum', 'inform', 'process', 'task', 'moreov', 'extend', 'concept', 'quantum', 'nonloc', 'quantum', 'channel', 'propos', 'measur', 'devic', 'independ', 'verif', 'protocol', 'quantum', 'channel', 'steer', 'purpos', 'adopt', 'assemblag', 'approach', 'util', 'choi', 'jamiolkowski', 'isomorph', 'prove', 'channel', 'assemblag', 'steerabl', 'dual', 'state', 'assemblag', 'steerabl', 'appli', 'canon', 'method', 'measur', 'devic', 'independ', 'verif', 'protocol', 'obtain', 'dual', 'state', 'assemblag', 'way', 'accomplish', 'measur', 'devic', 'independ', 'verif', 'channel', 'steer', 'inspect', 'effect', 'imperfect', 'quantum', 'state', 'generat', 'especi', 'use', 'obtain', 'choi', 'jamiolkowski', 'isomorph', 'result', 'show', 'channel', 'state', 'dualiti', 'steer', 'hold', 'long', 'quantum', 'state', 'bipartit', 'pure', 'state', 'full', 'schmidt', 'rank', 'furthermor', 'mixtur', 'quantum', 'state', 'local', 'nois', 'toler', 'proport', 'bound', 'steer', 'robust', 'research', 'open', 'question', 'regard', 'choi', 'jamiolkowski', 'isomorph', 'steer', 'list', 'expect', 'result', 'exploit', 'check', 'leakag', 'quantum', 'inform', 'quantum', 'channel', 'lossi', 'uncontrol', 'environ', 'introduct', 'ii', 'quantum', 'nonloc', 'introduct', 'categori', 'quantum', 'nonloc', 'extend', 'concept', 'quantum', 'steer', 'iii', 'measur', 'devic', 'independ', 'verif', 'quantum', 'nonloc', 'introduct', 'nonloc', 'game', 'semi', 'quantum', 'nonloc', 'game', 'quantum', 'refere', 'steer', 'game', 'iv', 'measur', 'devic', 'independ', 'loss', 'toler', 'verif', 'quantum', 'steer', 'introduct', 'loss', 'toler', 'qrs', 'game', 'loss', 'toler', 'steer', 'inequ', 'loss', 'toler', 'qrs', 'game', 'remark', 'channel', 'steer', 'incoher', 'channel', 'channel', 'steer', 'remark', 'vi', 'conclus', 'bibliographi', 'abstract', 'korean', '85docto', '전인우']}]\n",
      "['44716561', '97643030']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#query = \"retrieval quantum\"\n",
    "#tokenized_query = query.split(\" \")\n",
    "tokenized_query = [\"retrieval\", \"quantum\"]\n",
    "\n",
    "\n",
    "scoresBM25L = bm25L.get_scores(tokenized_query)\n",
    "#scoresBM25 = bm25.get_scores(tokenized_query)\n",
    "#print(scoresBM25L)\n",
    "\n",
    "ranked = bm25L.get_top_n(tokenized_query, all_documents, n=2)\n",
    "#r#anked_basic = bm25.get_top_n(tokenized_query, all_documents, n=2)\n",
    "\n",
    "print(ranked)\n",
    "#print(ranked_basic)\n",
    "\n",
    "ranked_doc_ids = [doc['id'] for doc in ranked]\n",
    "#ranked_doc_ids_basic = [doc['id'] for doc in ranked_basic]\n",
    "\n",
    "\n",
    "print(ranked_doc_ids)\n",
    "#print(ranked_doc_ids_basic)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cf2d86",
   "metadata": {},
   "source": [
    "# Evaluate \n",
    "\n",
    "- Search Information includes i) unique (anonymous) identifiers for individual user session; ii) search query; iii) returned results.\n",
    "- Click Information records, for each click, i) a unique (anonymous) identifier for individual user session; ii) the link that was clicked in the results list; iii) the position of clicked link in results list.\n",
    "\n",
    "queries:\n",
    "training queries\n",
    "│-- queries.txt # Tab-separated plain text file with queries and IDs \n",
    "- ID, search query\n",
    "\n",
    "qrels:\n",
    "│-- qrels.txt # Relevance judgments file in TREC format \n",
    "click information \n",
    "- ID, datum, dokumentID, relevanz\n",
    "\n",
    "(1) nDCG scores calculated on provided test sets. Such a classical evaluation measure is consistent with Web search, for which the discount emphasises the ordering of the top results.\n",
    "\n",
    "(2) Relative nDCG Drop (RnD) measured by computing the difference between snapshots test sets. This measure supports the evaluation of the impact of the data changes on the systems’ results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437f4d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse Queries.txt\n",
    "def load_queries(filepath):\n",
    "    queries = {}\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            query_id = parts[0]\n",
    "            query_text = parts[1]\n",
    "            queries[query_id] = query_text.split()  # Tokenize query\n",
    "    return queries\n",
    "\n",
    "\n",
    "\n",
    "# Parse qrels.txt\n",
    "def load_qrels(filepath):\n",
    "    qrels = defaultdict(dict)\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            query_id = parts[0]\n",
    "            doc_id = parts[2]\n",
    "            relevance = int(parts[3])\n",
    "            qrels[query_id][doc_id] = relevance\n",
    "    return qrels\n",
    "\n",
    "# Load files\n",
    "data_path_queries = os.path.join(data_path_abstract_q, \"queries.txt\")\n",
    "data_path_qrels = os.path.join(data_path_abstract_q, \"qrels.txt\")\n",
    "\n",
    "queries = load_queries(data_path_queries)\n",
    "qrels = load_qrels(data_path_qrels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
